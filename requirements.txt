# Core dependencies
torch>=2.0.0
transformers>=4.52.3
accelerate
toml

# VLLM (specific fork for Qwen2.5-Omni support)
# Note: Install VLLM from Qwen's fork for full Qwen2.5-Omni support
# git+https://github.com/fyabc/vllm.git@qwen2_omni_public

# Alternative: Use standard VLLM (text output only)
vllm>=0.8.5  # or just: vllm (for latest stable)

# Qwen utilities for multimodal processing
qwen-omni-utils[decord]

# Additional dependencies for Qwen2.5-Omni
setuptools_scm
torchdiffeq
resampy
x_transformers

# Optional: For video processing (if custom preprocessing needed)
# opencv-python
# librosa

# Optional: For better performance
# flash-attn>=2.0.0